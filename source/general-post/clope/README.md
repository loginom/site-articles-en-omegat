---
publish: 2020-01-14
---

# Кластеризация категорийных данных: масштабируемый алгоритм CLOPE

**Разбиение на группы со схожими характеристиками категорийных и транзакционных массивов данных в больших БД является важнейшей задачей Data Mining. Традиционные алгоритмы кластеризации в большинстве случаев не эффективны при обработке сверхбольших баз данных. В материале рассказывается о масштабируемом эвристическом алгоритме CLOPE, который позволяет проводить кластеризацию с высоким качеством и производительностью.**

## Введение и основные идеи

Задачи [кластеризации](https://wiki.loginom.ru/articles/clustering.html) больших массивов [категорийных данных](https://wiki.loginom.ru/articles/categorical-data.html) весьма актуальна для систем анализа данных. Категорийные данные встречаются в любых областях: производство, коммерция, маркетинг, медицина… Категорийные данные включают в себя и так называемые транзакционные данные: чеки в супермаркетах, логи посещений веб-ресурсов. Сюда же относится анализ и классификация текстовых документов ([Text Mining](https://wiki.loginom.ru/articles/text-mining.html)).

Здесь и далее под категорийными данными понимаются качественные характеристики объектов, измеренные в [шкале](https://wiki.loginom.ru/articles/scale-type.html) наименований. Напомним: при использовании шкалы наименований указывается только, одинаковы или нет объекты относительно измеряемого признака.

Применять для кластеризации объектов с категорийными признаками традиционные алгоритмы неэффективно, а часто — невозможно (подробнее см. материал «[Алгоритмы кластеризации на службе Data Mining»](https://loginom.ru/blog/data-mining-clustering)). Основные трудности связаны с высокой размерностью и гигантским объемом, которыми часто характеризуются такие базы данных.

Алгоритмы, основанные на парном вычислении расстояний ([k-means](https://wiki.loginom.ru/articles/k-means.html) и аналоги) эффективны в основном на числовых данных. Их производительность на массивах записей с большим количеством нечисловых факторов неудовлетворительная. И дело даже не столько в сложности задания метрики для вычисления расстояния между категорийными [атрибутами](https://wiki.loginom.ru/articles/attribute.html), сколько в том, что на каждой итерации алгоритма требуется попарно сравнивать объекты между собой, а итераций может быть очень много. Для таблиц с миллионами записей и тысячами полей это неприменимо.

Поэтому в настоящее время ведутся активные исследования в области разработки [масштабируемых (scalable) алгоритмов](https://wiki.loginom.ru/articles/scalable-algorithm.html) кластеризации категорийных и транзакционных данных. К ним предъявляются особые требования, а именно:

* минимально возможное количество «сканирований» таблицы базы данных;
* работа в ограниченном объеме оперативной памяти компьютера;
* работу алгоритма можно прервать с сохранением промежуточных результатов, чтобы продолжить вычисления позже;
* алгоритм должен работать, когда объекты из базы данных могут извлекаться только в режиме однонаправленного курсора (т.е. в режиме навигации по записям).

На сегодняшний день предложено свыше десятка методов для работы с категорийными данными, например, семейство иерархических кластерных алгоритмов. Но не всегда они удовлетворяют перечисленным выше требованиям. Одним из эффективных считается алгоритм LargeItem, который основан на оптимизации некоторого глобального критерия. Этот глобальный критерий использует параметр поддержки (в терминологии здесь много общего с алгоритмами для выявления [ассоциативных правил](https://wiki.loginom.ru/articles/association-rules.html)).

Вообще, вычисление глобального критерия делает алгоритм кластеризации во много раз быстрее, чем при использовании локального критерия при парном сравнении объектов, поэтому «глобализация» оценочной функции – один из путей получения масштабируемых алгоритмов.

Алгоритм CLOPE, который мы рассматриваем в данной статье, очень похож на LargeItem, но быстрее и проще в программной реализации. CLOPE предложен в 2002 году группой китайских ученых. При этом он обеспечивает более высокую производительность и лучшее качество кластеризации в сравнении с алгоритмом LargeItem и многими иерархическими алгоритмами.

Для начала формализуем рассматриваемую задачу кластеризации для категорийных данных. Все изложение будет идти как будто бы у нас в наличии имеется база транзакционных данных, а в конце материала будет показано, как с помощью CLOPE разбивать на [кластеры](https://wiki.loginom.ru/articles/cluster.html) любые категорийные массивы, работая с ними как с транзакционными.

Под термином [транзакция](https://wiki.loginom.ru/articles/transaction.html) здесь понимается некоторый произвольный набор объектов, будь это список ключевых слов статьи, товары, купленные в супермаркете, множество симптомов пациента, характерные фрагменты изображения и так далее. Задача кластеризации транзакционных данных состоит в получении такого разбиения всего множества транзакций, чтобы похожие транзакции оказались в одном кластере, а отличающиеся друг от друга — в разных кластерах.

В основе алгоритма кластеризации CLOPE лежит идея максимизации глобальной функции стоимости, которая повышает близость транзакций в кластерах при помощи увеличения параметра кластерной [гистограммы](https://wiki.loginom.ru/articles/histogram.html). Рассмотрим простой пример из 5 транзакций: { {% math %}(a,b){% endmath %}, {% math %}(a,b,c){% endmath %}, {% math %}(a,c,d){% endmath %}, {% math %}(d,e){% endmath %}, {% math %}(d,e,f){% endmath %} }. Представим себе, что мы хотим сравнить между собой следующие два разбиения на кластеры:

{  { {% math %}ab, abc, acd{% endmath %} }, { {% math %}de, def{% endmath %} } } , (1)

{ { {% math %}ab, abc{% endmath %} }, { {% math %}acd, de, def{% endmath %} } }, (2)

Для первого и второго вариантов разбиения в каждом кластере рассчитаем количество вхождений в него каждого элемента транзакции, а затем вычислим высоту ({% math %}H{% endmath %}) и ширину ({% math %}W{% endmath %}) кластера. Например, кластер { {% math %}ab, abc, acd{% endmath %} } имеет вхождения {% math %}a:3{% endmath %}, {% math %}b:2{% endmath %}, {% math %}c:2{% endmath %} с {% math %}H=2{% endmath %} и {% math %}W=4{% endmath %}. Для облегчения понимания на рис. 1 эти результаты показаны геометрически в виде гистограмм.

![Рисунок 1. Гистограммы двух разбиений](split.svg)

Качество двух разбиений оценим, проанализировав их высоту {% math %}H{% endmath %} и ширину {% math %}W{% endmath %}. Кластеры { {% math %}de, def{% endmath %} } и { {% math %}ab, abc{% endmath %} } имеют одинаковые гистограммы, следовательно, равноценны. Гистограмма для кластера { {% math %}ab, abc, acd{% endmath %} } содержит 4 различных элемента и имеет площадь 8 блоков ({% math %}H=2.0, H/W=0.5{% endmath %}), а кластер { {% math %}acd, de, def{% endmath %} } – 5 различных элементов с такой же площадью ({% math %}H=1.6, H/W=0.32{% endmath %}). Очевидно, что разбиение (1) лучше, поскольку обеспечивает большее наложение транзакций друг на друга (соответственно, параметр {% math %}H{% endmath %} там выше).

На основе такой очевидной и простой идеи геометрических гистограмм и работает алгоритм CLOPE (англ.: Clustering with sLOPE). Рассмотрим его подробнее в более формальном описании.

## Алгоритм CLOPE

Пусть имеется база транзакций {% math %}D{% endmath %}, состоящая из множества транзакций { {% math %}t_1,t_2,…,t_n{% endmath %} }. Каждая транзакция есть набор объектов { {% math %}i_1,…,i_m{% endmath %} }. Множество кластеров { {% math %}C_1,…,C_k{% endmath %} } есть разбиение множества { {% math %}t_1,…,t_n{% endmath %} }, такое, что {% math %}C_1 … C_k={% endmath %} { {% math %}t_1,…,t_n{% endmath %} } и {% math %}C_i\neq \varnothing  \wedge C_i \bigcap C_j = \varnothing{% endmath %}, для {% math %}1<=i{% endmath %}, {% math %}j<=k{% endmath %}. Каждый элемент {% math %}C_i{% endmath %} называется кластером, {% math %}n{% endmath %}, {% math %}m{% endmath %}, {% math %}k{% endmath %} – количество транзакций, количество объектов в базе транзакций и число кластеров соответственно.

Каждый кластер {% math %}C{% endmath %} имеет следующие характеристики:

* {% math %}D(C){% endmath %} – множество уникальных объектов;
* {% math %}Occ(i,C){% endmath %} – количество вхождений (частота) объекта {% math %}i{% endmath %} в кластер {% math %}C{% endmath %};
* {% math %}S(C)=\sum_{i\in\ D(C)}\ Occ\ (i, C)=\sum_{t_i\in C}\mid  t_i \mid{% endmath %}  
* {% math %}W(C) = |D(C)|{% endmath %};
* {% math %}H(C) = S(C)/W(C){% endmath %}.

Гистограммой кластера {% math %}C{% endmath %} называется графическое изображение его расчетных характеристик: по оси {% math %}OX{% endmath %} откладываются объекты кластера в порядке убывания величины {% math %}Occ(i,C){% endmath %}, а сама величина {% math %}Occ(i,C){% endmath %} – по оси {% math %}OY{% endmath %} (рис. 2).

![Рисунок 2. Иллюстрация гистограммы кластера](histogram.svg)

На рис. 2 {% math %}S(C)=8{% endmath %}, соответствует площади прямоугольника, ограниченного осями координат и пунктирной линией. Очевидно, что чем больше значение {% math %}H{% endmath %}, тем более «похожи» две транзакции. Поэтому алгоритм должен выбирать такие разбиения, которые максимизируют {% math %}H{% endmath %}.

Однако учитывать одно только значение высоты {% math %}H{% endmath %} недостаточно. Возьмем базу, состоящую из 2-х транзакций: { {% math %}abc, def{% endmath %} }. Они не содержат общих объектов, но разбиение { { {% math %}abc, def{% endmath %} } } и разбиение { { {% math %}abc{% endmath %} }, { {% math %}def{% endmath %} } } характеризуются одинаковой высотой {% math %}H=1{% endmath %}. Получается, оба варианта разбиения равноценны. Но если для оценки вместо {% math %}H(C){% endmath %} использовать градиент {% math %}G(C)=H(C)/W(C)=S(C)/W(C)^2{% endmath %}, то разбиение { { {% math %}abc{% endmath %} },{ {% math %}def{% endmath %} } } будет лучше (градиент каждого кластера равен 1/3 против 1/6 у разбиения { { {% math %}abc, def{% endmath %} } }).

Обобщив вышесказанное, запишем формулу для вычисления глобального критерия – функции стоимости {% math %}Profit(C){% endmath %}:

{% math %}Profit (C) = \frac {\sum_{i=1}^k G(C_i)\times\mid C_i\mid}{\sum_{i=1}^k \mid C_i\mid}=\frac {\sum_{i=1}^k \frac{S(C_i)}{W(C_i)^r}\times\mid C_i\mid}{\sum_{i=1}^k \mid C_i\mid}{% endmath %}

где:

* {% math %}|Ci|{% endmath %} – количество транзакций в {% math %}i{% endmath %}-том кластере
* {% math %}k{% endmath %} – количество кластеров
* {% math %}r{% endmath %} – положительное вещественное число большее 1.

С помощью параметра {% math %}r{% endmath %}, названного авторами CLOPE коэффициентом отталкивания (repulsion), регулируется уровень сходства транзакций внутри кластера, и, как следствие, финальное количество кластеров. Этот коэффициент подбирается пользователем. Чем больше {% math %}r{% endmath %}, тем ниже уровень сходства и тем больше кластеров будет сгенерировано.

Формальная постановка задачи кластеризации алгоритмом CLOPE выглядит следующим образом: для заданных {% math %}D{% endmath %} и {% math %}r{% endmath %} найти разбиение {% math %}C: Profit(C,r) -> max{% endmath %}.

## Реализация алгоритма

Предположим, что транзакции хранятся в таблице базы данных. Лучшее решение ищется в течение последовательного итеративного перебора записей базы данных. Поскольку критерий оптимизации имеет глобальный характер, основанный только на расчете {% math %}H{% endmath %} и {% math %}W{% endmath %}, производительность и скорость алгоритма будет значительно выше, чем при попарном сравнении транзакций.

Реализация алгоритма требует первого прохода по таблице транзакций для построения начального разбиения, определяемого функцией {% math %}Profit(C,r){% endmath %}. После этого требуется незначительное (1-3) количество дополнительных сканирований таблицы для повышения качества кластеризации и оптимизации функции стоимости. Если в текущем проходе по таблице изменений не произошло, то алгоритм прекращает свою работу. Псевдокод алгоритма имеет следующий вид.

1. // Фаза 1 – инициализация
2. &nbsp;&nbsp; Пока не конец
3. &nbsp;&nbsp;&nbsp;&nbsp;прочитать из таблицы следующую транзакцию [t, -];
4. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;положить t в существующий либо в новый кластер C<sub>i</sub>, который дает максимум Profit(C,r);
5. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;записать [t,i] в таблицу (номер кластера);
6. // Фаза 2 – Итерация
7. &nbsp;&nbsp;Повторять
8. &nbsp;&nbsp;&nbsp;&nbsp;перейти в начало таблицы;
9. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;moved := false;
10. &nbsp;&nbsp;&nbsp;&nbsp;пока не конец таблицы
11. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;читать [t,i];
12. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;положить t в существующий либо в новый кластер C<sub>j</sub>, который максимизирует Profit(C,r);
13. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;если C<sub>i</sub>&lt;&gt;C<sub>j</sub> тогда
14. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;записать [t,i];
15. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;moved := true;
16. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;пока (not moved).
17. удалить все пустые кластеры;

Как видно, алгоритм CLOPE является масштабируемым, поскольку способен работать в ограниченном объеме оперативной памяти компьютера. Во время работы в RAM хранится только текущая транзакция и небольшое количество информации по каждому кластеру, которая состоит из: количества транзакций {% math %}N{% endmath %}, числа уникальных объектов (или ширины кластера) {% math %}W{% endmath %}, простой хэш-таблицы для расчета {% math %}Occ(i,C){% endmath %} и значения {% math %}S{% endmath %} площади кластера. Они называются кластерными характеристиками (CF – cluster features). Для простоты обозначим их как свойства кластера {% math %}C{% endmath %}, например, {% math %}C.Occ[i]{% endmath %} означает число вхождений объекта {% math %}i{% endmath %} в кластер {% math %}C{% endmath %} и т.д. Можно посчитать, что для хранения частоты вхождений 10 тыс. объектов в 1 тыс. кластерах необходимо около 40 Мб оперативной памяти.

Для завершения реализации алгоритма нам нужны еще две функции, рассчитывающие прирост {% math %}Profit(C,r){% endmath %} при добавлении и удалении транзакции из кластера. Это легко сделать, зная величины {% math %}S{% endmath %}, {% math %}W{% endmath %} и {% math %}N{% endmath %} каждого кластера:

1. function DeltaAdd(C,t,r): double;
2. begin
3. &nbsp;&nbsp;S_new := C.S + t.ItemCount;
4. &nbsp;&nbsp;W_new := C.W;
5. &nbsp;&nbsp;for i:=0 to t.ItemCount–1 do
6. &nbsp;&nbsp;&nbsp;&nbsp; if (C.Occ[t.items[i]]=0) then W_new := W_new + 1;
7. &nbsp;&nbsp;result := S_new &#042; (C.N+1)/(W_new)<sup>r</sup> – C.S &#042; C.N/(C.W)<sup>r</sup>
8. end;

Здесь {% math %}t.Items[i]{% endmath %} – значение {% math %}i{% endmath %}-го объекта транзакции {% math %}t{% endmath %}. Заметим, что {% math %}DeltaAdd(C,t,r){% endmath %} при добавлении {% math %}t{% endmath %} в новый кластер равна {% math %}S/W^r{% endmath %}, где {% math %}S{% endmath %} и {% math %}W{% endmath %} – площадь и ширина кластера, состоящего из добавляемой транзакции {% math %}t{% endmath %}.

Реализация функции прироста {% math %}Profit(C,r){% endmath %} при удалении транзакции похожа на {% math %}DeltaAdd(C,t,r){% endmath %}, поэтому опустим ее подробный код.

Следующая теорема гарантирует корректность использования функции {% math %}DeltaAdd{% endmath %}.

**Теорема.** Если {% math %}DeltaAdd(Ci,t){% endmath %} есть максимум, то перемещение {% math %}t{% endmath %} в кластер {% math %}C_i{% endmath %} максимизирует {% math %}Profit(C,r){% endmath %}.

Теперь можно оценить вычислительную сложность алгоритма CLOPE. Пусть средняя длина транзакции равна {% math %}A{% endmath %}, общее число транзакций {% math %}N{% endmath %}, максимально возможное число кластеров {% math %}K{% endmath %}. Временная сложность одной итерации равна {% math %}O(N*K*A){% endmath %}, показывающая, что скорость работы алгоритма растет линейно с ростом кластеров и размера таблицы. Это делает алгоритм быстрым и эффективным на больших объемах.

Рассказав о реализации алгоритма, мы ничего не сказали о виде таблицы транзакций, чтобы можно было применять алгоритм CLOPE. CLOPE позволяет решать задачи кластеризации не только транзакционных данных, но и любых категорийных. Главное, чтобы все признаки объектов были измерены в шкале наименований.

Однако перед тем как запускать CLOPE, данные необходимо привести к нормализованному виду. Он может иметь вид бинарной матрицы образов, как в ассоциативных правилах, так и представлять собой взаимно однозначное отображение между множеством уникальных объектов {% math %}{u_1,…u_q}{% endmath %} таблицы и множеством целых чисел {% math %}{0,1,2,…,q-1}{% endmath %}.

## Задача о грибах

Задача о грибах (The mushroom dataset) – популярный тест, который применяют для оценки алгоритмов кластеризации категорийных наборов данных (доступен на [UCI machine learning repository](http://archive.ics.uci.edu/ml/index.php)). Тестовая выборка содержит 8124 записи с описанием 22 характеристик грибов двух классов: 4208 съедобных ({% math %}e{% endmath %}) и 3916 несъедобных ({% math %}p{% endmath %}) грибов. Файл выборки имеет следующий вид:

{% math %}p,x,s,n,t,p,f,c,n,k,e,e,s,s,w,w,p,w,o,p,k,s,u{% endmath %}

{% math %}e,x,s,y,t,a,f,c,b,k,e,c,s,s,w,w,p,w,o,p,n,n,g{% endmath %}

{% math %}e,b,s,w,t,l,f,c,b,n,e,c,s,s,w,w,p,w,o,p,n,n,m{% endmath %}

{% math %}p,x,y,w,t,p,f,c,n,n,e,e,s,s,w,w,p,w,o,p,k,s,u{% endmath %}

{% math %}e,x,s,g,f,n,f,w,b,k,t,e,s,s,w,w,p,w,o,e,n,a,g{% endmath %}

{% math %}..., ..., ...{% endmath %}

Общее количество уникальных характеристик объектов равно 116. 2480 записей имеют пропущенные значения в одном атрибуте. Описание набора данных — [https://archive.ics.uci.edu/ml/datasets/mushroom](https://archive.ics.uci.edu/ml/datasets/mushroom).

Если такой набор данных представить в описанном выше нормализованном виде, то получится 8124 транзакции, из которых 2408 будут длиной 21, а остальные – 22 элемента (пропущенные значения игнорируются). И теперь можно применить алгоритм CLOPE. Результат работы CLOPE при {% math %}r=2.6{% endmath %} для задачи о грибах после 1-ой итерации (фаза инициализации) представлен в таблице 1. 

При этом критерием качества работы алгоритма служит количество «грязных» кластеров, т.е. таких, в которых присутствуют как съедобные ({% math %}e{% endmath %}), так и несъедобные ({% math %}p{% endmath %}) грибы. Чем меньше таких кластеров, тем лучше. Из таблицы 1 видно, что уже после 1-ой итерации остался только 1 «грязный» кластер №18. Потребуется еще пару-тройку сканирований базы данных для получения финальной кластеризации. Очевидно, что кластер 12 исчезнет.

Детальное исследование работы алгоритма CLOPE, проведенное его авторами, показало высокое качество кластеризации в сравнении с другими алгоритмами, в т.ч. иерархическими. При этом по скорости работы и производительности он обгоняет их в несколько раз.

Таблица 1: результат работы CLOPE после 1 итерации.

| CLUSTER   | e         | p         |
|----------:|----------:|----------:|
| 1         |           | 256       |
| 2         | 512       |           |
| 3         | 768       |           |
| 4         | 96        |           |
| 5         | 96        |           |
| 6         | 192       |           |
| 7         | 1296      |           |
| 8         | 432       |           |
| 9         |           | 149       |
| 10        |           | 192       |
| 11        |           | 1146      |
| 12        |           | 1         |
| 13        |           | 288       |
| 14        | 192       |           |
| 15        |           | 223       |
| 16        | 48        |           |
| 17        |           | 72        |
| 18        | 48        | 32        |
| 19        |           | 8         |
| 20        |           | 8         |
| 21        |           | 1497      |
| 22        | 192       |           |
| 23        | 288       |           |
| 24        | 32        |           |
| 25        |           | 36        |
| 26        |           | 8         |
| 27        | 16        |           |
| Итого     | 4208      | 3916      |

## Области применения CLOPE

Алгоритм CLOPE предназначен для работы с транзакционными данными, но, как мы увидели, очень много наборов данных с категорийными атрибутами представляют собой транзакционные данные либо сводятся к ним. Ответы респондента в анкете, список ключевых слов документа, множество посещенных веб-ресурсов пользователя, симптомы больного, характеристики гриба – все это не что иное, как транзакция. Поэтому области применения CLOPE распространяются на все массивы категорийных баз данных.

Вообще, кластеризация транзакционных данных имеет много общего с анализом ассоциаций. Обе эти технологии [Data Mining](https://wiki.loginom.ru/articles/data-mining.html) выявляют скрытые зависимости в наборах данных. Но есть и отличия. С одной стороны, кластеризация дает общий взгляд на совокупность данных, тогда как ассоциативный анализ находит конкретные зависимости между атрибутами. С другой стороны, ассоциативные правила сразу пригодны для использования, тогда как кластеризация чаще всего используется как первая стадия анализа.

В завершение подчеркнем преимущества алгоритма CLOPE:

1. Высокие масштабируемость и скорость работы, а так же качество кластеризации, что достигается использованием глобального критерия оптимизации на основе максимизации градиента высоты гистограммы кластера. Он легко рассчитывается и интерпретируется. Во время работы алгоритм хранит в RAM небольшое количество информации по каждому кластеру и требует минимальное число сканирований набора данных. Это позволяет применять его для кластеризации огромных объемов категорийных данных (large categorical data sets);
2. CLOPE автоматически подбирает количество кластеров, причем это регулируется одним единственным параметром – коэффициентом отталкивания.

## Литература

1. Yang, Y., Guan, H., You. J. CLOPE: A fast and Effective Clustering Algorithm for Transactional Data In Proc. of SIGKDD’02, July 23-26, 2002, Edmonton, Alberta, Canada.
2. Wang, K., Xu, C.. Liu, B. Clustering transactions using large items. In Proc. CIKM’99, Kansas, Missouri, 1999.
